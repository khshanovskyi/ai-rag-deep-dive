from enum import StrEnum

import psycopg2
from psycopg2.extras import RealDictCursor

from task.embeddings.embeddings_client import DialEmbeddingsClient
from task.utils.text import chunk_text


class SearchMode(StrEnum):
    EUCLIDIAN_DISTANCE = "euclidean"  # Euclidean distance (<->)
    COSINE_DISTANCE = "cosine"  # Cosine distance (<=>)


class TextProcessor:
    """Processor for text documents that handles chunking, embedding, storing, and retrieval"""

    def __init__(self, embeddings_client: DialEmbeddingsClient, db_config: dict):
        self.embeddings_client = embeddings_client
        self.db_config = db_config

    def _get_connection(self):
        """Get database connection"""
        return psycopg2.connect(
            host=self.db_config['host'],
            port=self.db_config['port'],
            database=self.db_config['database'],
            user=self.db_config['user'],
            password=self.db_config['password']
        )

    def process_text_file(
            self,
            file_name: str,
            chunk_size: int,
            overlap: int,
            dimensions: int,
            truncate_table: bool = True,
    ):
        """
        Load content from file, chunk it, generate embeddings, and save to DB
        Args:
            file_name: path to file
            chunk_size: chunk size (min 10 chars)
            overlap: overlap chars between chunks
            dimensions: number of dimensions to store
            truncate_table: truncate table if true
        """

        if chunk_size < 10:
            raise ValueError("chunk_size must be at least 10")
        if overlap < 0:
            raise ValueError("overlap must be at least 0")
        if overlap >= chunk_size:
            raise ValueError("overlap should be lower than chunkSize")

        # TODO:
        #  1. Truncate table if truncate_table == True (call the `_truncate_table()` method)
        #  2. Open file and get content:
        #       a. with open(file_name, 'r', encoding='utf-8') as file:
        #       b. assign file.read() to `content`
        #  3. Generate text chunks from `content`, use method `chunk_text()`
        #  4. Generate dict with indexed embeddings for generated `chunks` via `embeddings_client.get_embeddings()`
        #     and assign them to `embeddings` variable

        print(f"Processing document: {file_name}")
        print(f"Total chunks: {len(chunks)}")
        print(f"Total embeddings: {len(embeddings)}")

        # TODO:
        #  1. Iterate through len of `chunks` (for i in range(len(chunks)))
        #  2. Save chunk with corresponding embedding to DB (use `_save_chunk()` method)


    def _truncate_table(self):
        """Truncate the vectors table"""
        # TODO:
        #  1. Open connection (with self._get_connection() as conn)
        #  2. Get `cursor` (with conn.cursor() as cursor)
        #  3. Execute query `TRUNCATE TABLE vectors` with `cursor`
        #  4. Make connection commit

    def _save_chunk(self, embedding: list[float], chunk: str, document_name: str):
        """Save chunk with embedding to database"""
        # TODO:
        #  1. Need convert embeddings list[float] to string and wrap embeddings into []
        #       - f"[{','.join(map(str, embedding))}]"
        #       - assign to `vector_string` variable
        #  2. Open connection to DB
        #  3. Get `cursor`
        #  4. Execute query:
        #       - query: INSERT INTO vectors (document_name, text, embedding) VALUES (%s, %s, %s::vector)
        #       - vars: (document_name, chunk, vector_string)
        #  5. Make connection commit



    def search(
            self,
            search_mode: SearchMode,
            user_request: str,
            top_k: int,
            score_threshold: float,
            dimensions: int
    ) -> list[str]:
        """
        Performs similarity search
        Args:
            search_mode: Search mode (Cosine or Euclidian distance)
            user_request: User request
            top_k: Number of results to return
            score_threshold: Minimum score to return (range 0.0 -> 1.0)
            dimensions: Number of dimensions to return (has to be the same as data persisted in VectorDB)
        """
        if top_k < 1:
            raise ValueError("top_k must be at least 1")
        if score_threshold < 0 or score_threshold > 1:
            raise ValueError("score_threshold must be in [0.0..., 0.99...] range")

        # TODO:
        #  1. Generate dict with indexed embeddings for generated `chunks` via `embeddings_client.get_embeddings()`.
        #     With this request we convert original user request into embedding for further vector search in DB.
        #  2. Need convert embeddings list[float] to string and wrap embeddings into []
        #       - f"[{','.join(map(str, embedding))}]"
        #       - assign to `vector_string` variable

        if search_mode == SearchMode.COSINE_DISTANCE:
            max_distance = 1.0 - score_threshold
        else:
            max_distance = float('inf') if score_threshold == 0 else (1.0 / score_threshold) - 1.0

        retrieved_chunks = []
        with self._get_connection() as conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                # TODO:
                #  1. Execute query:
                #       - query: Use `_get_search_query(search_mode)` method. Please take a look at query!
                #       - vars: (vector_string, vector_string, max_distance, top_k)
                #  2. Fetch all results with `cursor` into `results`
                results = None

                for row in results:
                    if search_mode == SearchMode.COSINE_DISTANCE:
                        similarity = 1.0 - row['distance']
                    else:
                        similarity = 1.0 / (1.0 + row['distance'])

                    print(f"---Similarity score: {similarity:.2f}---")
                    print(f"Data: {row['text']}\n")
                    retrieved_chunks.append(row['text'])

        return retrieved_chunks

    def _get_search_query(self, search_mode: SearchMode) -> str:
        return """SELECT text, embedding {mode} %s::vector AS distance
                  FROM vectors
                  WHERE embedding {mode} %s::vector <= %s
                  ORDER BY distance
                  LIMIT %s""".format(mode='<->' if search_mode == SearchMode.EUCLIDIAN_DISTANCE else '<=>')
